# -*- coding: utf-8 -*-
import sys
import uuid
import os
import re
import string
import json
from datetime import datetime
from typing import Optional, List, Dict, Union
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from config import API_URL, ARK_API_KEY, API_MODEL_NAME
from openmanus.mylib import run_agent

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    openai_api_base=API_URL,
    openai_api_key=ARK_API_KEY,
    model_name=API_MODEL_NAME
)
parser = JsonOutputParser()

# æ•°æ®æ¨¡å‹
class FileSpec(BaseModel):
    """æ–‡ä»¶ç”Ÿæˆè§„èŒƒ"""
    file_type: str = Field(..., description="æ–‡ä»¶ç±»å‹ï¼ˆcode/config/doc/resource/etcï¼‰")
    file_name: str = Field(..., description="æ–‡ä»¶åå«åç¼€")
    purpose: str = Field(..., description="æ–‡ä»¶ç”¨é€”æè¿°")
    template: Optional[str] = Field(
        default=None,
        description="æ–‡ä»¶å†…å®¹æ¨¡æ¿æˆ–å…³é”®é…ç½®è¯´æ˜"
    )
    dependencies: List[str] = Field(
        default_factory=list,
        description="ä¾èµ–çš„å…¶ä»–æ–‡ä»¶è·¯å¾„"
    )

class TaskNode(BaseModel):
    """ç»Ÿä¸€çš„ä»»åŠ¡èŠ‚ç‚¹æ¨¡å‹"""
    id: str = Field(
        default_factory=lambda: str(uuid.uuid4()),
        description="èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†"
    )
    description: str = Field(..., description="ä»»åŠ¡æè¿°")
    folder_name: Optional[str] = Field(
        default=None,
        description="ç”±æ¨¡å‹ç”Ÿæˆçš„æ–‡ä»¶å¤¹åç§°"
    )
    parent_id: Optional[str] = Field(
        default=None,
        description="çˆ¶èŠ‚ç‚¹IDï¼ˆæ ¹èŠ‚ç‚¹ä¸ºç©ºï¼‰"
    )
    children: List["TaskNode"] = Field(
        default_factory=list,
        description="å­ä»»åŠ¡èŠ‚ç‚¹åˆ—è¡¨"
    )
    file_specs: List[FileSpec] = Field(
        default_factory=list,
        description="éœ€è¦ç”Ÿæˆçš„æ–‡ä»¶è§„èŒƒ"
    )
    generated_files: List[str] = Field(
        default_factory=list,
        description="å·²ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„"
    )
    api_doc: Optional[str] = Field(
        default=None,
        description="èŠ‚ç‚¹åŠŸèƒ½æ–‡æ¡£ï¼ˆMarkdownæ ¼å¼ï¼‰"
    )
    status: str = Field(
        default="pending",
        description="ä»»åŠ¡çŠ¶æ€: pending/processing/completed/failed"
    )

# è§£å†³å‰å‘å¼•ç”¨é—®é¢˜
TaskNode.model_rebuild()


class UnifiedFileGenerator:
    """ç»Ÿä¸€æ–‡ä»¶ç”Ÿæˆå™¨"""
    def __init__(self, max_depth: int = 5):
        self.root = None
        self.node_map = {}
        self.indent_level = 0
        self.max_depth = max_depth  # æœ€å¤§é€’å½’æ·±åº¦é™åˆ¶

    def _print_process(self, message: str):
        """æ‰“å°å¸¦ç¼©è¿›å’Œæ—¶é—´æˆ³çš„å¤„ç†ä¿¡æ¯"""
        indent = "  " * self.indent_level
        print(f"{indent}ğŸš€ {datetime.now().strftime('%H:%M:%S')} - {message}")

    def _log_api_call(self, request_messages, response_content):
        """è®°å½•APIè°ƒç”¨æ—¥å¿—"""
        log_dir = "./log"
        os.makedirs(log_dir, exist_ok=True)
        
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "request": [{"content": msg.content} for msg in request_messages],
            "response": response_content
        }
        
        filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}.json"
        with open(os.path.join(log_dir, filename), "w", encoding="utf-8") as f:
            json.dump(log_entry, f, ensure_ascii=False, indent=2)

    async def build_tree(self, requirement: str) -> TaskNode:
        """æ„å»ºä»»åŠ¡æ ‘"""
        self._print_process(f"æ„å»ºä»»åŠ¡æ ‘ï¼š'{requirement}'")
        self.root = TaskNode(description=requirement)
        self.node_map[self.root.id] = self.root
        await self._process_node(self.root, current_depth=0)
        return self.root

    async def _process_node(self, node: TaskNode, current_depth: int):
        """é€’å½’å¤„ç†ä»»åŠ¡èŠ‚ç‚¹"""
        if node.status == "completed":
            return
    
        if current_depth >= self.max_depth:
            self._print_process(f"âš ï¸ è¾¾åˆ°æœ€å¤§æ·±åº¦é™åˆ¶ {self.max_depth}ï¼Œåœæ­¢åˆ†è§£")
            node.status = "completed"
            return
    
        node.status = "processing"
        self.indent_level += 1
        self._print_process(f"å¤„ç†èŠ‚ç‚¹ [{node.id[:8]}]ï¼ˆæ·±åº¦ {current_depth}ï¼‰ï¼š{node.description}")
        
        response = await self._analyze_requirement(node)
        node.folder_name = response.get('folder_name', f"node_{node.id[:6]}")  # è®¾ç½®æ–‡ä»¶å¤¹åç§°
        
        if response.get('type') == 'direct':
            node.file_specs = [FileSpec(**f) for f in response['files']]
        else:
            # å…ˆå¤„ç†å­ä»»åŠ¡
            for subtask in response.get('subtasks', []):
                child = TaskNode(
                    description=subtask['description'],
                    folder_name=subtask.get('folder_name'),
                    parent_id=node.id,
                )
                if 'files' in subtask:
                    child.file_specs = [FileSpec(**f) for f in subtask['files']]
                node.children.append(child)
                self.node_map[child.id] = child
                await self._process_node(child, current_depth + 1)
            
            # å¤„ç†å½“å‰èŠ‚ç‚¹æ–‡ä»¶ï¼ˆåœ¨å­èŠ‚ç‚¹ä¹‹åå¤„ç†ä»¥å®ç°ä¾èµ–è§£æï¼‰
            if 'files' in response:
                node.file_specs = [FileSpec(**f) for f in response['files']]
    
        await self._generate_files(node)
        node.status = "completed" if all(f in node.generated_files for f in self._get_expected_files(node)) else "failed"
        self.indent_level -= 1

    async def _analyze_requirement(self, node: TaskNode) -> Dict:
        """åˆ†æç”¨æˆ·éœ€æ±‚ç”Ÿæˆå®ç°æ–¹æ¡ˆ"""
        parent_path = self._get_node_path(node.parent_id) if node.parent_id else ""
        
        prompt_template = ChatPromptTemplate.from_template(
            """ä½œä¸ºå…¨æ ˆå¼€å‘ä¸“å®¶ï¼Œåˆ†æéœ€æ±‚å¹¶è§„åˆ’æ–‡ä»¶ç»“æ„ã€‚éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. å•ä¸ªèŠ‚ç‚¹æœ€å¤šç”Ÿæˆ5ä¸ªæ ¸å¿ƒæ–‡ä»¶
2. çˆ¶èŠ‚ç‚¹è´Ÿè´£æ¡†æ¶ï¼Œå­èŠ‚ç‚¹å¤„ç†å…·ä½“æ¨¡å—
3. èµ„æºæ–‡ä»¶é›†ä¸­æ”¾åœ¨resourcesç›®å½•
4. ç¡®ä¿æ–‡ä»¶è·¯å¾„ç¬¦åˆå½“å‰èŠ‚ç‚¹ä½ç½®ï¼š{current_path}
5. ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆç®€æ´çš„è‹±æ–‡æ–‡ä»¶å¤¹åï¼ˆä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿ï¼‰
6. ç”¨JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ï¼š
- type: directï¼ˆç›´æ¥å®ç°ï¼‰æˆ– splitï¼ˆéœ€è¦æ‹†åˆ†ï¼‰
- folder_name: å½“å‰èŠ‚ç‚¹çš„æ–‡ä»¶å¤¹åç§°
- filesï¼ˆå½“å‰èŠ‚ç‚¹éœ€è¦ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨ï¼‰
- subtasksï¼ˆéœ€è¦æ‹†åˆ†çš„å­ä»»åŠ¡åˆ—è¡¨ï¼‰

è¿”å›ç¤ºä¾‹ï¼š
{{
    "type": "split",
    "folder_name": "flappy_bird_main",
    "files": [
        {{
            "file_type": "code",
            "file_name": "main.py",
            "purpose": "ç¨‹åºå…¥å£",
            "template": "import pygame\\n..."
        }}
    ],
    "subtasks": [
        {{
            "description": "å®ç°æ¸¸æˆè§’è‰²ç³»ç»Ÿ",
            "folder_name": "character_system",
            "files": [
                {{
                    "file_type": "code", 
                    "file_name": "character.py",
                    "purpose": "è§’è‰²ç±»å®šä¹‰"
                }}
            ]
        }}
    ]
}}

å½“å‰èŠ‚ç‚¹ä»»åŠ¡ï¼š{requirement}"""
        )
        
        messages = prompt_template.format_messages(
            requirement=node.description,
            current_path=self._get_node_path(node.id)
        )
        
        response = await llm.ainvoke(messages)
        self._log_api_call(messages, response.content)
        return parser.invoke(response)

    def _get_expected_files(self, node: TaskNode) -> List[str]:
        """è·å–èŠ‚ç‚¹é¢„æœŸç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„"""
        return [os.path.join(self._get_node_path(node.id), f.file_name) 
                for f in node.file_specs]

    async def _generate_files(self, node: TaskNode):
        """ç”ŸæˆèŠ‚ç‚¹å…³è”çš„æ‰€æœ‰æ–‡ä»¶"""
        node_dir = self._get_node_path(node.id)
        os.makedirs(node_dir, exist_ok=True)
        
        for file_spec in node.file_specs:
            file_path = os.path.join(node_dir, file_spec.file_name)
            if os.path.exists(file_path):
                continue
                
            context = {
                "node_description": node.description,
                "file_spec": file_spec.dict(),
                "dependencies": [
                    os.path.join(self._get_node_path(node.parent_id), dep)
                    for dep in file_spec.dependencies
                ],
                "save_path": file_path
            }
            
            gen_success = await run_agent(json.dumps(context), max_steps=50)
            if gen_success:
                node.generated_files.append(file_path)
                self._print_process(f"ğŸ“„ ç”Ÿæˆæ–‡ä»¶ï¼š{file_path}")
            else:
                self._print_process(f"âŒ æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼š{file_spec.file_name}")

    def _get_node_path(self, node_id: str) -> str:
        """è·å–èŠ‚ç‚¹å¯¹åº”çš„æ–‡ä»¶è·¯å¾„"""
        path_parts = []
        current_node = self.node_map.get(node_id)
        
        while current_node:
            if current_node.folder_name:
                # æ¸…ç†éæ³•å­—ç¬¦å¹¶ç”Ÿæˆæœ‰æ•ˆæ–‡ä»¶å¤¹åç§°
                valid_name = re.sub(r'[^a-z0-9_-]', '', current_node.folder_name.lower())
                if not valid_name:
                    valid_name = f"node_{current_node.id[:6]}"
                path_parts.append(valid_name)
            else:
                path_parts.append(f"node_{current_node.id[:6]}")
            current_node = self.node_map.get(current_node.parent_id) if current_node.parent_id else None
        
        path_parts.reverse()
        return os.path.join("generated", *path_parts)

async def main():
    from gen_openmanus_config import init_config
    init_config()
    generator = UnifiedFileGenerator(max_depth=3)
    task_tree = await generator.build_tree(
        "å†™ä¸ªpythonç¨‹åºï¼Œè¾“å‡º0åˆ°100"
    )
    print("\nç”Ÿæˆæ–‡ä»¶åˆ—è¡¨ï¼š")
    for f in task_tree.generated_files:
        print(f" - {f}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())

